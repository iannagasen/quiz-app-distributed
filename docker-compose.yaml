version: '2.1'

services:

  question:
    build: src/backend/microservices/question-service
    mem_limit: 512m
    environment:
      - "SPRING_PROFILES_ACTIVE=docker"
    ports:
      - 8080:8080
    depends_on:
      mysql:
        condition: service_healthy

  mysql:
    image: mysql:8.0.32
    mem_limit: 512m
    ports:
      - "3307:3306"
    environment:
      MYSQL_ROOT_PASSWORD: rootpwd
      # MYSQL_DATABASE: question-db
      MYSQL_USER: user
      MYSQL_PASSWORD: pwd
    healthcheck:
      test: "/usr/bin/mysql --user=user --password=pwd --execute \"SHOW DATABASES;\""
      interval: 5s
      timeout: 2s
      retries: 60
    volumes:
      - ./dump-scripts:/docker-entrypoint-initdb.d

  
  kafka:
    image: bitnami/kafka:3.3.2
    restart: "no"
    container_name: kafka
    mem_limit: 1024m
    ports:
      # - 9092:9092
      - 9094:9094
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      ## kafka server
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:2181,EXTERNAL://:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
        
        # https://github.com/bitnami/containers/tree/main/bitnami/kafka#accessing-apache-kafka-with-internal-and-external-clients
      # - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      # - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      # - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT

      - KAFKA_BROKER_ID=1
      ## 1, check the KAFKA_CFG_NODE_ID
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=1
      ## generate a cluster id
      - KAFKA_KRAFT_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      ## Note, as this a non root container,the mounted files and directories must have the proper permissions for the UID 1001.
      ## sudo chown -R 1001:1001 ./kafka
      - kafka-data:/bitnami/kafka

  elasticsearch:
    image: elasticsearch:8.9.0
    container_name: elasticsearch
    restart: no
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
    # command: >
    #   bash -c "
    #     elasticsearch -p /tmp/epid & /bin/bash /utils/wait-for-it.sh -t 0 localhost:9200 -- curl -XPUT 'http://127.0.0.1:9200/springboot-app-index' -d @index.json; 
    #     kill $(cat /tmp/epid) && wait $(cat /tmp/epid); 
    #     exit 0;
    #   "
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      # single node cluster
      discovery.type: single-node
      xpack.security.enabled: false
      bootstrap.memory_lock: true
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - elk

  logstash:
    image: logstash:8.9.0
    container_name: logstash
    restart: no
    volumes:
      - ./elk/logstash/config/:/usr/share/logstash/config/
      - ./elk/logstash/pipeline/:/usr/share/logstash/pipeline/
    command: logstash -f /usr/share/logstash/pipeline/logstash.conf
    # when logstash is started, it should use the config file from logstash.conf
    depends_on:
      - elasticsearch
    ports:
      - 9600:9600
      - 5044:5044
      - 5000:5000/tcp
      - 5000:500/udp
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTICSEARCH_URL: http://elasticsearch:9200
    networks:
      - elk

  kibana:
    image: kibana:8.9.0
    container_name: kibana
    restart: no
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    depends_on:
      - elasticsearch
    networks:
      - elk


volumes:
  kafka-data:
    driver: local
  elastic-data:
    driver: local

networks:
  elk:
    driver: bridge